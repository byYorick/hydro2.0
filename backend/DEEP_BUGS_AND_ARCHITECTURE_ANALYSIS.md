# –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∞–≥–æ–≤ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Backend

**–î–∞—Ç–∞:** 8 –¥–µ–∫–∞–±—Ä—è 2025  
**–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:** Deep Dive - Concurrency, Race Conditions, Deadlocks, Scalability

---

## üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ë–ê–ì–ò

### 1. Race Condition –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–æ–¥

**–§–∞–π–ª:** `backend/laravel/app/Services/NodeRegistryService.php:133-137`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```php
// –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å uid
$counter = 1;
while (DeviceNode::where('uid', $uid)->exists()) {  // ‚Üê SELECT
    $uid = $this->generateNodeUid($hardwareId, $nodeType, $counter);
    $counter++;
}

$node = new DeviceNode();  // ‚Üê INSERT
$node->uid = $uid;
// ...
$node->save();
```

**–°—Ü–µ–Ω–∞—Ä–∏–π –∞—Ç–∞–∫–∏:**
1. –î–≤–µ –Ω–æ–¥—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º `hardware_id` —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
2. –û–±–µ –ø—Ä–æ—Ö–æ–¥—è—Ç –ø—Ä–æ–≤–µ—Ä–∫—É `exists()` –∏ –ø–æ–ª—É—á–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π `uid`
3. –û–±–µ –ø—ã—Ç–∞—é—Ç—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
4. –û–¥–Ω–∞ –∏–∑ –Ω–∏—Ö —É–ø–∞–¥–µ—Ç —Å `UNIQUE constraint violation`

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå –°–±–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–æ–¥—ã
- ‚ùå –ü–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö –æ hardware_id
- ‚ùå –ù–æ–¥–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ

**–†–µ—à–µ–Ω–∏–µ:**

```php
// backend/laravel/app/Services/NodeRegistryService.php

public function registerNodeFromHello(array $helloData): DeviceNode
{
    return DB::transaction(function () use ($helloData) {
        $hardwareId = $helloData['hardware_id'] ?? null;
        if (!$hardwareId) {
            throw new \InvalidArgumentException('hardware_id is required');
        }
        
        // ‚úÖ –ò–°–ü–û–õ–¨–ó–£–ï–ú PESSIMISTIC LOCK –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
        // SELECT FOR UPDATE –±–ª–æ–∫–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–æ –∫–æ–Ω—Ü–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        $node = DeviceNode::where('hardware_id', $hardwareId)
            ->lockForUpdate()  // ‚Üê PESSIMISTIC LOCK
            ->first();
        
        if ($node) {
            // –£–∑–µ–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –æ–±–Ω–æ–≤–ª—è–µ–º
            $this->updateNodeAttributes($node, $helloData);
            $node->save();
            return $node;
        }
        
        // –£–∑–µ–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - —Å–æ–∑–¥–∞–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π
        $maxAttempts = 5;
        $attempt = 0;
        
        while ($attempt < $maxAttempts) {
            try {
                $nodeType = $helloData['node_type'] ?? 'unknown';
                $uid = $this->generateNodeUid($hardwareId, $nodeType, $attempt);
                
                // –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å —É–∑–µ–ª
                $node = new DeviceNode();
                $node->uid = $uid;
                $node->hardware_id = $hardwareId;
                $node->type = $nodeType;
                $node->first_seen_at = now();
                $node->lifecycle_state = NodeLifecycleState::REGISTERED_BACKEND;
                
                $this->updateNodeAttributes($node, $helloData);
                
                $node->save();
                
                // –£—Å–ø–µ—Ö - –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                Log::info('Node created successfully', [
                    'node_id' => $node->id,
                    'uid' => $uid,
                    'attempt' => $attempt,
                ]);
                
                break;
                
            } catch (\Illuminate\Database\UniqueConstraintViolationException $e) {
                // UID —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π counter
                $attempt++;
                
                if ($attempt >= $maxAttempts) {
                    Log::error('Failed to generate unique UID after max attempts', [
                        'hardware_id' => $hardwareId,
                        'max_attempts' => $maxAttempts,
                    ]);
                    throw new \RuntimeException('Failed to register node: UID generation failed');
                }
                
                Log::warning('UID collision detected, retrying', [
                    'hardware_id' => $hardwareId,
                    'attempt' => $attempt,
                ]);
                
                // –ö–æ—Ä–æ—Ç–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è backoff)
                usleep(100000 * $attempt); // 100ms, 200ms, 300ms, ...
            }
        }
        
        // –ö–∞–Ω–∞–ª—ã –ù–ï —Å–æ–∑–¥–∞—ë–º –∏–∑ capabilities: –Ω–æ–¥–∞ –ø—É–±–ª–∏–∫—É–µ—Ç –∏—Ö –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞ (–æ–Ω–∏ –∑–∞—à–∏—Ç—ã –≤ –ø—Ä–æ—à–∏–≤–∫–µ)
        
        return $node;
    });
}

private function updateNodeAttributes(DeviceNode $node, array $helloData): void
{
    if (isset($helloData['fw_version'])) {
        $node->fw_version = $helloData['fw_version'];
    }
    
    if (isset($helloData['hardware_revision'])) {
        $node->hardware_revision = $helloData['hardware_revision'];
    }
    
    $provisioningMeta = $helloData['provisioning_meta'] ?? [];
    if (isset($provisioningMeta['node_name'])) {
        $node->name = $provisioningMeta['node_name'];
    }
    
    $node->validated = true;
}
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô  
**Effort:** 2-3 —á–∞—Å–∞

---

### 2. Cache::lock() –Ω–µ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–æ—Ç–µ—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏

**–§–∞–π–ª:** `backend/laravel/app/Jobs/PublishNodeConfigJob.php:47-57`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```php
$lockKey = "lock:{$this->dedupeKey}";
$lock = Cache::lock($lockKey, 60); // –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ 60 —Å–µ–∫—É–Ω–¥

if (! $lock->get()) {
    Log::debug('PublishNodeConfigJob: Skipping duplicate job', [...]);
    return; // –£–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
}

try {
    $node = DeviceNode::find($this->nodeId);  // ‚Üê –ù–ï–¢ DB-LEVEL LOCK
    // ... –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥–∞ ...
} finally {
    $lock->release();
}
```

**–°—Ü–µ–Ω–∞—Ä–∏–∏ —Å–±–æ—è:**

1. **Redis —É–ø–∞–ª** ‚Üí –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø–æ—Ç–µ—Ä—è–Ω–∞ ‚Üí –¥–≤–µ –¥–∂–æ–±—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
2. **Queue worker —É–ø–∞–ª** ‚Üí –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞ ‚Üí —Å–ª–µ–¥—É—é—â–∏–µ –¥–∂–æ–±—ã –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –Ω–∞ 60 —Å–µ–∫—É–Ω–¥
3. **Clock skew** –º–µ–∂–¥—É —Å–µ—Ä–≤–µ—Ä–∞–º–∏ ‚Üí –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥–∞
- ‚ùå –õ–∏—à–Ω–∏–µ MQTT —Å–æ–æ–±—â–µ–Ω–∏—è
- ‚ùå –ù–æ–¥–∞ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫–æ–Ω—Ñ–∏–≥

**–†–µ—à–µ–Ω–∏–µ:**

```php
public function handle(NodeConfigService $configService): void
{
    // ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º DB-level lock –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    return DB::transaction(function () use ($configService) {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º ADVISORY LOCK PostgreSQL –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        // –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç—å –¥–∞–∂–µ –ø—Ä–∏ —Å–±–æ–µ Redis
        $lockKey = crc32("publish_config:{$this->nodeId}");
        
        // pg_try_advisory_xact_lock –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ –∫–æ–Ω—Ü–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        $locked = DB::selectOne("SELECT pg_try_advisory_xact_lock(?) as locked", [$lockKey]);
        
        if (!$locked->locked) {
            Log::debug('PublishNodeConfigJob: Skipping duplicate job (locked)', [
                'node_id' => $this->nodeId,
            ]);
            return;
        }
        
        // ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º SELECT FOR UPDATE –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        $node = DeviceNode::where('id', $this->nodeId)
            ->lockForUpdate()
            ->first();
        
        if (!$node) {
            Log::warning('PublishNodeConfigJob: Node not found', [
                'node_id' => $this->nodeId,
            ]);
            return;
        }
        
        // ... –æ—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ...
        
        // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥
        $config = $configService->generateNodeConfig($node, null, true);
        
        // –ü—É–±–ª–∏–∫—É–µ–º —á–µ—Ä–µ–∑ MQTT
        $this->publishToMqtt($node, $config);
    });
}
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º Cache::lock –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫):**

```php
public function handle(NodeConfigService $configService): void
{
    // –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Redis (–¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
    $lockKey = "lock:{$this->dedupeKey}";
    $lock = Cache::lock($lockKey, 60);

    if (!$lock->get()) {
        return; // –ë—ã—Å—Ç—Ä—ã–π –≤—ã—Ö–æ–¥ –±–µ–∑ DB –∑–∞–ø—Ä–æ—Å–∞
    }

    try {
        // ‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ —á–µ—Ä–µ–∑ DB lock
        return DB::transaction(function () use ($configService) {
            $lockKey = crc32("publish_config:{$this->nodeId}");
            $locked = DB::selectOne("SELECT pg_try_advisory_xact_lock(?) as locked", [$lockKey]);
            
            if (!$locked->locked) {
                return; // –£–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –¥—Ä—É–≥–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            }
            
            $node = DeviceNode::where('id', $this->nodeId)
                ->lockForUpdate()
                ->first();
            
            if (!$node) {
                return;
            }
            
            // ... –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥–∞ ...
        });
    } finally {
        $lock->release();
    }
}
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô  
**Effort:** 3-4 —á–∞—Å–∞

---

### 3. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Optimistic Locking –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–æ–¥

**–§–∞–π–ª:** `backend/laravel/app/Services/NodeService.php:51-180`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```php
public function update(DeviceNode $node, array $data): DeviceNode
{
    return DB::transaction(function () use ($node, $data) {
        Log::info('NodeService::update START', [...]);
        
        $oldZoneId = $node->zone_id;  // ‚Üê –ú–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–º
        
        // ... 100+ —Å—Ç—Ä–æ–∫ –ª–æ–≥–∏–∫–∏ ...
        
        $node->update($data);  // ‚Üê –ü–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        
        // ...
    });
}
```

**–°—Ü–µ–Ω–∞—Ä–∏–π:**
1. **Process A** —á–∏—Ç–∞–µ—Ç –Ω–æ–¥—É (zone_id = 1)
2. **Process B** —á–∏—Ç–∞–µ—Ç –Ω–æ–¥—É (zone_id = 1)
3. **Process A** –æ–±–Ω–æ–≤–ª—è–µ—Ç zone_id = 2
4. **Process B** –æ–±–Ω–æ–≤–ª—è–µ—Ç zone_id = 3
5. **–†–µ–∑—É–ª—å—Ç–∞—Ç:** zone_id = 3 (–∏–∑–º–µ–Ω–µ–Ω–∏–µ Process A –ø–æ—Ç–µ—Ä—è–Ω–æ)

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå Lost updates
- ‚ùå –ù–æ–¥–∞ –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –≤ –Ω–µ–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
- ‚ùå –ö–æ–Ω—Ñ–∏–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –Ω–µ –¥–ª—è —Ç–æ–π –∑–æ–Ω—ã

**–†–µ—à–µ–Ω–∏–µ:**

#### ‚úÖ –°–ø–æ—Å–æ–± 1: –î–æ–±–∞–≤–∏—Ç—å version column (Optimistic Locking)

```php
// –ú–∏–≥—Ä–∞—Ü–∏—è
Schema::table('nodes', function (Blueprint $table) {
    $table->unsignedBigInteger('version')->default(0);
    $table->index('version');
});

// Model
class DeviceNode extends Model
{
    protected $fillable = [
        // ...
        'version',
    ];
    
    /**
     * –û–±–Ω–æ–≤–∏—Ç—å —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–µ—Ä—Å–∏–∏
     */
    public function updateWithVersionCheck(array $attributes): bool
    {
        $currentVersion = $this->version;
        $this->version = $currentVersion + 1;
        
        foreach ($attributes as $key => $value) {
            if ($key !== 'version') {
                $this->$key = $value;
            }
        }
        
        // UPDATE nodes SET ..., version = version + 1 WHERE id = ? AND version = ?
        $affected = DB::update(
            "UPDATE nodes SET " . $this->buildUpdateClause($attributes) . 
            ", version = version + 1, updated_at = NOW() " .
            "WHERE id = ? AND version = ?",
            array_merge(array_values($attributes), [$this->id, $currentVersion])
        );
        
        if ($affected === 0) {
            // –í–µ—Ä—Å–∏—è –∏–∑–º–µ–Ω–∏–ª–∞—Å—å - –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            return false;
        }
        
        return true;
    }
}

// Service
public function update(DeviceNode $node, array $data): DeviceNode
{
    $maxRetries = 3;
    $attempt = 0;
    
    while ($attempt < $maxRetries) {
        $attempt++;
        
        try {
            return DB::transaction(function () use ($node, $data) {
                // –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–¥—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏
                $node->refresh();
                
                // ... –ª–æ–≥–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ...
                
                // –û–±–Ω–æ–≤–ª—è–µ–º —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–µ—Ä—Å–∏–∏
                $success = $node->updateWithVersionCheck($data);
                
                if (!$success) {
                    throw new \App\Exceptions\OptimisticLockException(
                        "Node was modified by another process. Please retry."
                    );
                }
                
                return $node->fresh();
            });
        } catch (\App\Exceptions\OptimisticLockException $e) {
            if ($attempt >= $maxRetries) {
                Log::error('Failed to update node after max retries', [
                    'node_id' => $node->id,
                    'attempts' => $attempt,
                ]);
                throw $e;
            }
            
            Log::warning('Optimistic lock conflict, retrying', [
                'node_id' => $node->id,
                'attempt' => $attempt,
            ]);
            
            // Exponential backoff
            usleep(100000 * $attempt);
        }
    }
}
```

#### ‚úÖ –°–ø–æ—Å–æ–± 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SELECT FOR UPDATE

```php
public function update(DeviceNode $node, array $data): DeviceNode
{
    return DB::transaction(function () use ($node, $data) {
        // ‚úÖ –ë–ª–æ–∫–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        $node = DeviceNode::where('id', $node->id)
            ->lockForUpdate()  // ‚Üê PESSIMISTIC LOCK
            ->first();
        
        if (!$node) {
            throw new \RuntimeException('Node not found');
        }
        
        // ... –ª–æ–≥–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ...
        
        $node->update($data);
        
        return $node->fresh();
    });
}
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô  
**Effort:** 4-6 —á–∞—Å–æ–≤ (—Å —Ç–µ—Å—Ç–∞–º–∏)

---

## üü† –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –ü–†–û–ë–õ–ï–ú–´

### 4. –ù–µ—Ç —è–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è isolation level –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö

**–ü—Ä–æ–±–ª–µ–º–∞:**

```php
DB::transaction(function () use ($node, $data) {
    // –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π isolation level (READ COMMITTED –≤ PostgreSQL)
    // –≠—Ç–æ –Ω–µ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç phantom reads –∏ –¥—Ä—É–≥–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π
});
```

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå **Non-repeatable reads:** –û–¥–Ω–∞ –∏ —Ç–∞ –∂–µ SELECT –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å —Ä–∞–∑–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
- ‚ùå **Phantom reads:** COUNT(*) –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
- ‚ùå **Write skew:** –î–≤–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –º–æ–≥—É—Ç –Ω–∞—Ä—É—à–∏—Ç—å –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞

**–ü—Ä–∏–º–µ—Ä write skew:**

```php
// –ü—Ä–∞–≤–∏–ª–æ: –í –∑–æ–Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∞–∫—Å–∏–º—É–º 1 –Ω–æ–¥–∞ —Ç–∏–ø–∞ 'ph'

// Transaction 1:
$count = DeviceNode::where('zone_id', 1)->where('type', 'ph')->count(); // 0
if ($count < 1) {
    $node1->zone_id = 1;
    $node1->save();
}

// Transaction 2 (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ):
$count = DeviceNode::where('zone_id', 1)->where('type', 'ph')->count(); // 0
if ($count < 1) {
    $node2->zone_id = 1;
    $node2->save();
}

// –†–µ–∑—É–ª—å—Ç–∞—Ç: 2 –Ω–æ–¥—ã —Ç–∏–ø–∞ 'ph' –≤ –∑–æ–Ω–µ 1 (–ø—Ä–∞–≤–∏–ª–æ –Ω–∞—Ä—É—à–µ–Ω–æ)
```

**–†–µ—à–µ–Ω–∏–µ:**

```php
// config/database.php
'pgsql' => [
    'driver' => 'pgsql',
    // ...
    'options' => [
        PDO::ATTR_EMULATE_PREPARES => false,
    ],
],

// –î–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º SERIALIZABLE
public function update(DeviceNode $node, array $data): DeviceNode
{
    return DB::transaction(function () use ($node, $data) {
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º SERIALIZABLE –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∏–∑–æ–ª—è—Ü–∏–∏
        DB::statement('SET TRANSACTION ISOLATION LEVEL SERIALIZABLE');
        
        // ... –ª–æ–≥–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ...
        
    }, 5); // 5 –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ serialization failure
}

// –î–ª—è –æ–±—ã—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å REPEATABLE READ
public function show(DeviceNode $node): array
{
    return DB::transaction(function () use ($node) {
        DB::statement('SET TRANSACTION ISOLATION LEVEL REPEATABLE READ');
        
        // –í—Å–µ SELECT –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —É–≤–∏–¥—è—Ç snapshot –Ω–∞ –º–æ–º–µ–Ω—Ç –Ω–∞—á–∞–ª–∞
        $node->load(['zone', 'channels']);
        
        return $node->toArray();
    });
}
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
- **SERIALIZABLE** –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è, –ø—Ä–∏–≤—è–∑–∫–∞, swap)
- **REPEATABLE READ** –¥–ª—è —á—Ç–µ–Ω–∏—è —Å –≥–∞—Ä–∞–Ω—Ç–∏—è–º–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
- **READ COMMITTED** (–¥–µ—Ñ–æ–ª—Ç) –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† –í–´–°–û–ö–ò–ô  
**Effort:** 1-2 –¥–Ω—è (+ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–ª—è—Ü–∏–∏)

---

### 5. –£–∑–∫–æ–µ –º–µ—Å—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: MAX_CONCURRENT_ZONES = 5

**–§–∞–π–ª:** `backend/services/automation-engine/main.py:441`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```python
await process_zones_parallel(
    zones_to_check,
    zone_service,
    max_concurrent=automation_settings.MAX_CONCURRENT_ZONES  # = 5
)
```

**–†–∞—Å—á–µ—Ç:** 
- 5 –∑–æ–Ω –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- –¶–∏–∫–ª –∫–∞–∂–¥—ã–µ 15 —Å–µ–∫—É–Ω–¥
- –ú–∞–∫—Å–∏–º—É–º `5 * (60 / 15) = 20 –∑–æ–Ω/–º–∏–Ω—É—Ç—É`
- **–ú–∞–∫—Å–∏–º—É–º ~300 –∑–æ–Ω** –ø—Ä–∏ —Ü–∏–∫–ª–µ 15 —Å–µ–∫—É–Ω–¥

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏:**
- ‚ùå –ü—Ä–∏ 500 –∑–æ–Ω–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–π–º–µ—Ç 100 —Å–µ–∫—É–Ω–¥ (6+ —Ü–∏–∫–ª–æ–≤)
- ‚ùå –ó–∞–¥–µ—Ä–∂–∫–∞ —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è
- ‚ùå –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ backlog

**–†–µ—à–µ–Ω–∏–µ:**

#### ‚úÖ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# config/settings.py
@dataclass
class AutomationSettings:
    MAX_CONCURRENT_ZONES: int = int(os.getenv("MAX_CONCURRENT_ZONES", "10"))
    TARGET_CYCLE_TIME_SEC: int = int(os.getenv("TARGET_CYCLE_TIME_SEC", "15"))
    ADAPTIVE_CONCURRENCY: bool = os.getenv("ADAPTIVE_CONCURRENCY", "true").lower() == "true"

async def calculate_optimal_concurrency(
    total_zones: int,
    target_cycle_time: int,
    avg_zone_processing_time: float
) -> int:
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–æ–Ω.
    
    –§–æ—Ä–º—É–ª–∞: concurrency = (total_zones * avg_time) / target_cycle_time
    """
    optimal = math.ceil((total_zones * avg_zone_processing_time) / target_cycle_time)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
    min_concurrency = 5
    max_concurrency = 50  # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
    
    return max(min_concurrency, min(optimal, max_concurrency))

async def process_zones_adaptive(zones: List[Dict[str, Any]], zone_service: ZoneAutomationService):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–æ–Ω —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å—é."""
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = ZONE_PROCESSING_TIME.get_sample_value()
    avg_time = stats.sum / stats.count if stats.count > 0 else 1.0
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å
    optimal_concurrency = await calculate_optimal_concurrency(
        total_zones=len(zones),
        target_cycle_time=automation_settings.TARGET_CYCLE_TIME_SEC,
        avg_zone_processing_time=avg_time
    )
    
    logger.info(f"Adaptive concurrency: {optimal_concurrency} zones (avg time: {avg_time:.2f}s)")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å—é
    await process_zones_parallel(zones, zone_service, max_concurrent=optimal_concurrency)

# –ú–µ—Ç—Ä–∏–∫–∏
ZONE_PROCESSING_TIME = Histogram(
    "zone_processing_time_seconds",
    "Time to process a single zone",
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

OPTIMAL_CONCURRENCY = Gauge(
    "optimal_concurrency_zones",
    "Calculated optimal concurrency for zone processing"
)
```

#### ‚úÖ –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

```yaml
# docker-compose.prod.yml
services:
  automation-engine:
    # ...
    deploy:
      replicas: 3  # 3 –∏–Ω—Å—Ç–∞–Ω—Å–∞
    environment:
      - ZONE_SHARD_ID=${ZONE_SHARD_ID}  # 0, 1, 2
      - ZONE_SHARD_TOTAL=3
```

```python
# main.py
async def get_zones_for_shard() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å –∑–æ–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —à–∞—Ä–¥–∞."""
    shard_id = int(os.getenv("ZONE_SHARD_ID", "0"))
    shard_total = int(os.getenv("ZONE_SHARD_TOTAL", "1"))
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–æ–Ω—ã
    rows = await fetch("""
        SELECT id, name FROM zones 
        WHERE status = 'active'
        ORDER BY id
    """)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —à–∞—Ä–¥—É
    zones = []
    for row in rows:
        zone_id = row['id']
        if (zone_id % shard_total) == shard_id:
            zones.append({'id': zone_id, 'name': row['name']})
    
    logger.info(f"Shard {shard_id}/{shard_total}: Processing {len(zones)} zones")
    
    return zones
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† –í–´–°–û–ö–ò–ô  
**Effort:** 2-3 –¥–Ω—è

---

### 6. asyncio.gather –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ partial failures

**–§–∞–π–ª:** `backend/services/automation-engine/main.py:260`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```python
tasks = []
async with semaphore:
    for zone in zones:
        tasks.append(process_zone(zone, zone_service))

await asyncio.gather(*tasks, return_exceptions=True)  # ‚Üê Exceptions —Å–∫—Ä—ã—Ç—ã
```

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå –û—à–∏–±–∫–∏ –≤ –æ–¥–Ω–æ–π –∑–æ–Ω–µ –º–æ–ª—á–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è
- ‚ùå –ù–µ—Ç –∞–ª–µ—Ä—Ç–æ–≤ –æ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–æ–Ω–∞—Ö
- ‚ùå –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

**–†–µ—à–µ–Ω–∏–µ:**

```python
async def process_zones_parallel(
    zones: List[Dict[str, Any]],
    zone_service: ZoneAutomationService,
    max_concurrent: int = 5
) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–æ–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫.
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {
            'total': int,
            'success': int,
            'failed': int,
            'errors': List[Dict]
        }
    """
    semaphore = asyncio.Semaphore(max_concurrent)
    
    results = {
        'total': len(zones),
        'success': 0,
        'failed': 0,
        'errors': []
    }
    
    async def process_with_tracking(zone: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–æ–Ω—ã —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
        zone_id = zone.get('id')
        
        try:
            async with semaphore:
                start = time.time()
                
                await zone_service.process_zone(zone_id)
                
                duration = time.time() - start
                ZONE_PROCESSING_TIME.observe(duration)
                results['success'] += 1
                
                logger.debug(f"Zone {zone_id} processed successfully ({duration:.2f}s)")
                
        except Exception as e:
            results['failed'] += 1
            results['errors'].append({
                'zone_id': zone_id,
                'zone_name': zone.get('name', 'unknown'),
                'error': str(e),
                'error_type': type(e).__name__,
                'timestamp': datetime.utcnow().isoformat()
            })
            
            ZONE_PROCESSING_ERRORS.labels(
                zone_id=zone_id,
                error_type=type(e).__name__
            ).inc()
            
            logger.error(
                f"Error processing zone {zone_id}: {e}",
                exc_info=True,
                extra={'zone_id': zone_id, 'zone_name': zone.get('name')}
            )
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∑–æ–Ω—ã
    tasks = [process_with_tracking(zone) for zone in zones]
    await asyncio.gather(*tasks)
    
    # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    logger.info(
        f"Zone processing completed: {results['success']}/{results['total']} success, "
        f"{results['failed']} failed"
    )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –æ—à–∏–±–æ–∫
    if results['failed'] > 0:
        failure_rate = results['failed'] / results['total']
        
        if failure_rate > 0.1:  # >10% –æ—à–∏–±–æ–∫
            await send_alert(
                severity='warning' if failure_rate < 0.3 else 'critical',
                title=f"High zone processing failure rate: {failure_rate:.1%}",
                details={
                    'total': results['total'],
                    'failed': results['failed'],
                    'errors': results['errors'][:10]  # –ü–µ—Ä–≤—ã–µ 10 –æ—à–∏–±–æ–∫
                }
            )
    
    return results

# –ú–µ—Ç—Ä–∏–∫–∏
ZONE_PROCESSING_ERRORS = Counter(
    "zone_processing_errors_total",
    "Errors during zone processing",
    ["zone_id", "error_type"]
)
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† –í–´–°–û–ö–ò–ô  
**Effort:** 2-3 —á–∞—Å–∞

---

## üü° –ü–†–û–ë–õ–ï–ú–´ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò

### 7. N+1 –∑–∞–ø—Ä–æ—Å—ã –≤ history-logger –ø—Ä–∏ –±–∞—Ç—á–∏–Ω–≥–µ

**–§–∞–π–ª:** `backend/services/history-logger/main.py:514-600`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```python
async def process_telemetry_queue():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ –±–∞—Ç—á–∞–º–∏."""
    while not shutdown_event.is_set():
        try:
            # –î–æ—Å—Ç–∞—ë–º –±–∞—Ç—á –∏–∑ Redis
            batch = await telemetry_queue.pop_batch(s.telemetry_batch_size)
            
            for item in batch:
                # ‚ùå N –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ä–µ–∑–æ–ª–≤–∞ zone_id
                zone_id = await resolve_zone_id(item.zone_uid)  # ‚Üê SELECT
                node_id = await resolve_node_id(item.node_uid)  # ‚Üê SELECT
                
                # –í—Å—Ç–∞–≤–∫–∞ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
                await execute("""
                    INSERT INTO telemetry_samples (zone_id, node_id, metric_type, value, ts)
                    VALUES ($1, $2, $3, $4, $5)
                """, zone_id, node_id, item.metric_type, item.value, item.ts)
```

**–ü—Ä–∏ –±–∞—Ç—á–µ –∏–∑ 200 —ç–ª–µ–º–µ–Ω—Ç–æ–≤:**
- 200 * 2 = 400 SELECT –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ä–µ–∑–æ–ª–≤–∞ zone_id/node_id
- 200 INSERT –∑–∞–ø—Ä–æ—Å–æ–≤
- **–ò—Ç–æ–≥–æ: 600 –∑–∞–ø—Ä–æ—Å–æ–≤** –≤–º–µ—Å—Ç–æ ~3

**–†–µ—à–µ–Ω–∏–µ:**

```python
async def process_telemetry_queue():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ –±–∞—Ç—á–∞–º–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""
    
    # –ö–µ—à –¥–ª—è —Ä–µ–∑–æ–ª–≤–∞ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 60 —Å–µ–∫—É–Ω–¥)
    zone_cache = {}
    node_cache = {}
    cache_last_update = 0
    cache_ttl = 60
    
    while not shutdown_event.is_set():
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à –µ—Å–ª–∏ —É—Å—Ç–∞—Ä–µ–ª
            current_time = time.time()
            if current_time - cache_last_update > cache_ttl:
                await refresh_caches(zone_cache, node_cache)
                cache_last_update = current_time
            
            # –î–æ—Å—Ç–∞—ë–º –±–∞—Ç—á –∏–∑ Redis
            batch = await telemetry_queue.pop_batch(s.telemetry_batch_size)
            
            if not batch:
                await asyncio.sleep(0.1)
                continue
            
            # ‚úÖ –ë–∞—Ç—á-—Ä–µ–∑–æ–ª–≤ zone_id –∏ node_id
            await resolve_batch_ids(batch, zone_cache, node_cache)
            
            # ‚úÖ –ë–∞—Ç—á-–≤—Å—Ç–∞–≤–∫–∞ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
            await insert_telemetry_batch(batch)
            
            TELEM_PROCESSED.inc(len(batch))
            TELEM_BATCH_SIZE.observe(len(batch))
            
        except Exception as e:
            logger.error(f"Error processing telemetry queue: {e}", exc_info=True)
            await asyncio.sleep(1)

async def refresh_caches(zone_cache: Dict, node_cache: Dict):
    """–û–±–Ω–æ–≤–∏—Ç—å –∫–µ—à–∏ zone_id –∏ node_id."""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–æ–Ω—ã (–æ–±—ã—á–Ω–æ <1000, –ø–æ–º–µ—â–∞—é—Ç—Å—è –≤ –ø–∞–º—è—Ç—å)
    zones = await fetch("SELECT id, uid FROM zones")
    zone_cache.clear()
    for zone in zones:
        zone_cache[zone['uid']] = zone['id']
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–æ–¥—ã (–æ–±—ã—á–Ω–æ <10000, –ø–æ–º–µ—â–∞—é—Ç—Å—è –≤ –ø–∞–º—è—Ç—å)
    nodes = await fetch("SELECT id, uid FROM nodes")
    node_cache.clear()
    for node in nodes:
        node_cache[node['uid']] = node['id']
    
    logger.info(f"Cache refreshed: {len(zone_cache)} zones, {len(node_cache)} nodes")

async def resolve_batch_ids(
    batch: List[TelemetryQueueItem],
    zone_cache: Dict,
    node_cache: Dict
):
    """–†–µ–∑–æ–ª–≤–∏—Ç—å zone_id –∏ node_id –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞."""
    
    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ zone_uid –∏ node_uid, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–µ—à–µ
    missing_zones = set()
    missing_nodes = set()
    
    for item in batch:
        if item.zone_uid and item.zone_uid not in zone_cache:
            missing_zones.add(item.zone_uid)
        if item.node_uid and item.node_uid not in node_cache:
            missing_nodes.add(item.node_uid)
    
    # ‚úÖ –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∑–æ–Ω
    if missing_zones:
        zones = await fetch(
            "SELECT id, uid FROM zones WHERE uid = ANY($1)",
            list(missing_zones)
        )
        for zone in zones:
            zone_cache[zone['uid']] = zone['id']
    
    # ‚úÖ –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –Ω–æ–¥
    if missing_nodes:
        nodes = await fetch(
            "SELECT id, uid FROM nodes WHERE uid = ANY($1)",
            list(missing_nodes)
        )
        for node in nodes:
            node_cache[node['uid']] = node['id']
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º zone_id –∏ node_id –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –±–∞—Ç—á–∞
    for item in batch:
        item.zone_id = zone_cache.get(item.zone_uid)
        item.node_id = node_cache.get(item.node_uid)

async def insert_telemetry_batch(batch: List[TelemetryQueueItem]):
    """–í—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–ª–µ–º–µ—Ç—Ä–∏—é –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º."""
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º VALUES –¥–ª—è batch insert
    values = []
    params = []
    param_idx = 1
    
    for item in batch:
        if item.zone_id is None:
            logger.warning(f"Skipping telemetry: zone not found for {item.zone_uid}")
            continue
        
        values.append(f"(${param_idx}, ${param_idx+1}, ${param_idx+2}, ${param_idx+3}, ${param_idx+4}, ${param_idx+5})")
        params.extend([
            item.zone_id,
            item.node_id,
            item.metric_type,
            item.channel,
            item.value,
            item.ts
        ])
        param_idx += 6
    
    if not values:
        return
    
    # ‚úÖ –û–¥–∏–Ω INSERT –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞
    query = f"""
        INSERT INTO telemetry_samples (zone_id, node_id, metric_type, channel, value, ts)
        VALUES {', '.join(values)}
        ON CONFLICT DO NOTHING
    """
    
    await execute(query, *params)
    
    # ‚úÖ Batch update telemetry_last
    await update_telemetry_last_batch(batch)

async def update_telemetry_last_batch(batch: List[TelemetryQueueItem]):
    """–û–±–Ω–æ–≤–∏—Ç—å telemetry_last –¥–ª—è –±–∞—Ç—á–∞."""
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ (zone_id, metric_type) - –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    last_values = {}
    for item in batch:
        if item.zone_id:
            key = (item.zone_id, item.metric_type)
            if key not in last_values or item.ts > last_values[key].ts:
                last_values[key] = item
    
    # ‚úÖ Batch upsert
    if last_values:
        values = []
        params = []
        param_idx = 1
        
        for item in last_values.values():
            values.append(f"(${param_idx}, ${param_idx+1}, ${param_idx+2}, ${param_idx+3}, ${param_idx+4}, NOW())")
            params.extend([
                item.zone_id,
                item.node_id or -1,
                item.metric_type,
                item.channel,
                item.value
            ])
            param_idx += 5
        
        query = f"""
            INSERT INTO telemetry_last (zone_id, node_id, metric_type, channel, value, updated_at)
            VALUES {', '.join(values)}
            ON CONFLICT (zone_id, metric_type)
            DO UPDATE SET 
                node_id = EXCLUDED.node_id,
                channel = EXCLUDED.channel, 
                value = EXCLUDED.value, 
                updated_at = NOW()
        """
        
        await execute(query, *params)
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –°–†–ï–î–ù–ò–ô  
**Effort:** 4-6 —á–∞—Å–æ–≤

---

### 8. Redis queue overflow –±–µ–∑ –∞–ª–µ—Ä—Ç–æ–≤

**–§–∞–π–ª:** `backend/services/common/redis_queue.py:91-113`

**–ü—Ä–æ–±–ª–µ–º–∞:**

```python
async def push(self, item: TelemetryQueueItem) -> bool:
    """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –æ—á–µ—Ä–µ–¥—å."""
    try:
        await self._ensure_client()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
        size = await self._client.llen(self.QUEUE_KEY)
        if size >= self.MAX_QUEUE_SIZE:  # 10000
            logger.warning(f"Telemetry queue is full ({size} items), dropping message")
            return False  # ‚ùå –ú–æ–ª—á–∞ —Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        await self._client.rpush(self.QUEUE_KEY, item.to_json())
        return True
```

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- ‚ùå –¢–µ–ª–µ–º–µ—Ç—Ä–∏—è —Ç–µ—Ä—è–µ—Ç—Å—è –±–µ–∑ –∞–ª–µ—Ä—Ç–æ–≤
- ‚ùå –ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è dropped messages
- ‚ùå –ù–µ—Ç backpressure mechanism

**–†–µ—à–µ–Ω–∏–µ:**

```python
# common/redis_queue.py

# –ú–µ—Ç—Ä–∏–∫–∏
QUEUE_SIZE = Gauge("telemetry_queue_size", "Current size of telemetry queue")
QUEUE_DROPPED = Counter("telemetry_queue_dropped_total", "Dropped messages due to queue overflow")
QUEUE_OVERFLOW_ALERTS = Counter("telemetry_queue_overflow_alerts_total", "Number of overflow alerts sent")

async def push(self, item: TelemetryQueueItem) -> bool:
    """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –æ—á–µ—Ä–µ–¥—å —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º."""
    try:
        await self._ensure_client()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
        size = await self._client.llen(self.QUEUE_KEY)
        QUEUE_SIZE.set(size)
        
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
        if size >= self.MAX_QUEUE_SIZE:
            QUEUE_DROPPED.inc()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
            if size >= self.MAX_QUEUE_SIZE * 0.95:  # 95% –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
                await self._send_overflow_alert(size)
            
            logger.warning(
                f"Telemetry queue is full ({size} items), dropping message",
                extra={
                    'queue_size': size,
                    'max_size': self.MAX_QUEUE_SIZE,
                    'dropped_item': {
                        'zone_uid': item.zone_uid,
                        'metric_type': item.metric_type,
                    }
                }
            )
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        await self._client.rpush(self.QUEUE_KEY, item.to_json())
        return True
        
    except Exception as e:
        logger.error(f"Failed to push to telemetry queue: {e}", exc_info=True)
        return False

async def _send_overflow_alert(self, current_size: int):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∞–ª–µ—Ä—Ç –æ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏ –æ—á–µ—Ä–µ–¥–∏."""
    
    # Throttling: –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—â–µ 1 —Ä–∞–∑–∞ –≤ –º–∏–Ω—É—Ç—É
    throttle_key = "alert_throttle:queue_overflow"
    if await self._client.exists(throttle_key):
        return
    
    await self._client.setex(throttle_key, 60, "1")  # 60 —Å–µ–∫—É–Ω–¥
    
    QUEUE_OVERFLOW_ALERTS.inc()
    
    logger.error(
        f"CRITICAL: Telemetry queue overflow! Size: {current_size}/{self.MAX_QUEUE_SIZE}",
        extra={
            'queue_size': current_size,
            'max_size': self.MAX_QUEUE_SIZE,
            'utilization': f"{current_size/self.MAX_QUEUE_SIZE:.1%}"
        }
    )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ alerting —Å–∏—Å—Ç–µ–º—É
    await create_zone_event(
        zone_id=None,  # –°–∏—Å—Ç–µ–º–Ω—ã–π –∞–ª–µ—Ä—Ç
        event_type='system_queue_overflow',
        details={
            'queue_size': current_size,
            'max_size': self.MAX_QUEUE_SIZE,
            'severity': 'critical'
        }
    )
```

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: Backpressure mechanism**

```python
# history-logger/main.py

async def handle_telemetry(topic: str, payload: bytes):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ —Å backpressure."""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏
    size = await telemetry_queue.size()
    utilization = size / telemetry_queue.MAX_QUEUE_SIZE
    
    # –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ >90%, –ø—Ä–∏–º–µ–Ω—è–µ–º sampling
    if utilization > 0.9:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º 50% —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–∏ 90-95% –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º 80% —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–∏ >95% –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏
        sample_rate = 0.5 if utilization < 0.95 else 0.2
        
        if random.random() > sample_rate:
            TELEMETRY_DROPPED.labels(reason="backpressure").inc()
            logger.warning(
                f"Dropping telemetry due to backpressure (queue {utilization:.1%} full)",
                extra={'topic': topic, 'queue_utilization': utilization}
            )
            return
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    data = _parse_json(payload)
    if not data:
        return
    
    # ... –æ—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ ...
```

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –°–†–ï–î–ù–ò–ô  
**Effort:** 2-3 —á–∞—Å–∞

---

## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞

| # | –ü—Ä–æ–±–ª–µ–º–∞ | –¢–∏–ø | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | Effort | Impact |
|---|----------|-----|-----------|--------|--------|
| 1 | Race condition –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–æ–¥ | Bug | üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô | 2-3—á | Data loss |
| 2 | Cache::lock() –Ω–µ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç —Å–±–æ–µ–≤ | Bug | üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô | 3-4—á | Duplicate configs |
| 3 | –ù–µ—Ç Optimistic Locking | Bug | üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô | 4-6—á | Lost updates |
| 4 | –ù–µ—Ç —è–≤–Ω–æ–≥–æ isolation level | Architecture | üü† –í–´–°–û–ö–ò–ô | 1-2–¥ | Write skew |
| 5 | MAX_CONCURRENT_ZONES = 5 | Scalability | üü† –í–´–°–û–ö–ò–ô | 2-3–¥ | Bottleneck |
| 6 | asyncio.gather –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ | Bug | üü† –í–´–°–û–ö–ò–ô | 2-3—á | Silent failures |
| 7 | N+1 –∑–∞–ø—Ä–æ—Å—ã –≤ –±–∞—Ç—á–∏–Ω–≥–µ | Performance | üü° –°–†–ï–î–ù–ò–ô | 4-6—á | Slow processing |
| 8 | Redis queue overflow –±–µ–∑ –∞–ª–µ—Ä—Ç–æ–≤ | Bug | üü° –°–†–ï–î–ù–ò–ô | 2-3—á | Data loss |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π

### –°–ø—Ä–∏–Ω—Ç 1 (–ù–µ–¥–µ–ª—è 1): –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –±–∞–≥–∏

1. **Race condition –ø—Ä–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–æ–¥** (2-3—á)
2. **Cache::lock() ‚Üí DB locks** (3-4—á)
3. **Optimistic Locking** (4-6—á)
4. **asyncio.gather error handling** (2-3—á)

**–ò—Ç–æ–≥–æ:** ~15 —á–∞—Å–æ–≤

### –°–ø—Ä–∏–Ω—Ç 2 (–ù–µ–¥–µ–ª—è 2): –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **Isolation levels** (1-2–¥)
2. **Adaptive concurrency** (2-3–¥)
3. **N+1 queries optimization** (4-6—á)

**–ò—Ç–æ–≥–æ:** ~5 –¥–Ω–µ–π

### –°–ø—Ä–∏–Ω—Ç 3 (–ù–µ–¥–µ–ª—è 3): Monitoring –∏ –∞–ª–µ—Ä—Ç—ã

1. **Redis queue overflow alerts** (2-3—á)
2. **Backpressure mechanism** (2-3—á)
3. **Load testing** (2–¥)

**–ò—Ç–æ–≥–æ:** ~3 –¥–Ω—è

---

## üìà –û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ | –ü–æ—Å–ª–µ |
|---------|----|----|
| Data loss incidents | 2-3/–º–µ—Å—è—Ü | 0 |
| Concurrent update errors | 5-10/–¥–µ–Ω—å | 0 |
| Max zones supported | 300 | 5000+ |
| Telemetry latency (p99) | 2000ms | 500ms |
| Queue overflow incidents | 1-2/–Ω–µ–¥–µ–ª—é | 0 |

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 8 –¥–µ–∫–∞–±—Ä—è 2025  
**–ê–≤—Ç–æ—Ä:** AI Deep Dive Analyzer  
**–í–µ—Ä—Å–∏—è:** 1.0
